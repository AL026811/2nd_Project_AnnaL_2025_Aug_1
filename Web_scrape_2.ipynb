{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9558a9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from selenium) (2025.7.14)\n",
      "Requirement already satisfied: typing-extensions~=4.9 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from trio~=0.17->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.16.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: selenium in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from selenium) (2025.7.14)\n",
      "Requirement already satisfied: typing-extensions~=4.9 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from trio~=0.17->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from webdriver-manager) (2.32.4)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from webdriver-manager) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from webdriver-manager) (2.32.4)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from webdriver-manager) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from requests->webdriver-manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from requests->webdriver-manager) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\annah\\appdata\\local\\anaconda3\\envs\\py3_12\\lib\\site-packages (from requests->webdriver-manager) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install pandas selenium webdriver-manager\n",
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e685ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import sqlite3\n",
    "import random \n",
    "# import requests\n",
    "\n",
    "service = Service(executable_path=ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de000998",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days= 60) # Get 10 years of data 365*10\n",
    "\n",
    "period1 = int(start_date.timestamp())\n",
    "period2 = int(end_date.timestamp())\n",
    "\n",
    "\n",
    "def scrape_yahoo_finance(stock_symbol):\n",
    "    website_link = f'https://finance.yahoo.com/quote/{stock_symbol}/history/?period1={period1}&period2={period2}'\n",
    "\n",
    "    # r = requests.get(website_link)\n",
    "\n",
    "    # if r.status_code == 200:\n",
    "    #     print('Pass')\n",
    "    # else:\n",
    "    #     print('Fail')\n",
    "    #     raise ExceptionType('Error Message')\n",
    "    \n",
    "    # driver = webdriver.Chrome()\n",
    "    # driver.get(website_link)\n",
    "    \n",
    "    # #Wait for the page to load\n",
    "    # time.sleep(random.uniform(5,10))  # Add a random deloy to avoid bot detection\n",
    "\n",
    "    # try: \n",
    "#     \"\"\"\n",
    "#     Data Extraction:\n",
    "# Uses an XPath to locate the historical data table. Important: Inspect the Yahoo Finance page to ensure this XPath is still correct. Yahoo Finance's HTML structure can change, which would break the scraper.\n",
    "# table.get_attribute('outerHTML') gets the HTML content of the table.\n",
    "# pd.read_html(table_html)[0] uses pandas to parse the HTML table into a DataFrame.\n",
    "# Adds a 'Stock' column to the DataFrame to identify the source of the data.\n",
    "# Handles a potential \"Dividends Only\" header row that can appear on some stock's historical data pages.\n",
    "# \"\"\"\n",
    "        # # Extract the historical data table (need verified, asked GPT)\n",
    "        # table = driver.find_element(By.XPATH, '//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div[2]/table')\n",
    "        # table_html = table.get_attribute('outerHTML')\n",
    "        # df = pd.read_html(table_html)[0]\n",
    "\n",
    "        # # Add stock column\n",
    "        # sanitized_symbol = stock_symbol.replace('^',\"_\")\n",
    "        # df['Stock'] = sanitized_symbol\n",
    "        \n",
    "        # #Reorder columns to have 'Stock' as the first column\n",
    "        # cols = df.columns.tolist()\n",
    "        # cols = ['Stock'] + cols[:-1] \n",
    "        # df = df[cols]\n",
    "        \n",
    "        # #Needed?\n",
    "        # #Handle the 'Dividends Only header row'\n",
    "        # if 'Dividends Only' in df.columns: \n",
    "        #     df = df.drop('Dividends Only, axis = 1')\n",
    "\n",
    "    driver.get(website_link)\n",
    "\n",
    "    # Wait for the page to load (adjust time as needed)\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    try:\n",
    "        # Locate the table rows\n",
    "        table_rows = driver.find_elements(By.CSS_SELECTOR, 'table.yf-1jecxey tbody tr')\n",
    "\n",
    "        # Iterate through each row and extract data\n",
    "        for row in table_rows:\n",
    "            # Locate the table cells in each row\n",
    "            cells = row.find_elements(By.CSS_SELECTOR, 'td.yf-1jecxey')\n",
    "            \n",
    "            # Extract the text from each cell\n",
    "            row_data = [cell.text for cell in cells]\n",
    "            if row_data:  # Only append if row_data is not empty\n",
    "                data.append(row_data)\n",
    "\n",
    "        if data: \n",
    "            columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "            # sanitized_symbol = stock_symbol.replace('^','_')\n",
    "           \n",
    "            df = pd.DataFrame(data, columns = columns)\n",
    "            df['Stock_Symbol'] = stock_symbol\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data for {stock_symbol}: {e}\")\n",
    "        data = None # Return None if there was an error\n",
    "    finally: \n",
    "        driver.quit()\n",
    "    return data\n",
    "              \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9f21bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for AAPL...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_sql'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m sanitized_symbol = stock.replace(\u001b[33m'\u001b[39m\u001b[33m^\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stock_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Store the data in the SQLIT database\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     stock_data.to_sql(sanitized_symbo, conn, if_exist = \u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m, index =\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mData for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m successfully stored in database.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m: \n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'to_sql'"
     ]
    }
   ],
   "source": [
    "# stock_symbols = ['AAPL', 'BA', 'T', 'MGM', 'AMZN', 'IBM', 'TSLA', 'GOOG', '^GSPC']\n",
    "stock_symbols = ['AAPL', '^GSPC'] # test\n",
    "\n",
    "conn = sqlite3.connect(\"stocks.db\")\n",
    "\n",
    "for stock in stock_symbols: \n",
    "    print(f\"Scraping data for {stock}...\")\n",
    "    stock_data = scrape_yahoo_finance(stock)\n",
    "    sanitized_symbol = stock.replace('^','_')\n",
    "    if stock_data is not None: \n",
    "        # Store the data in the SQLIT database\n",
    "        stock_data.to_sql(sanitized_symbo, conn, if_exist = \"replace\", index =True)\n",
    "        print(f\"Data for {stock} successfully stored in database.\")\n",
    "    else: \n",
    "        print(f\"No data found or error occurred for {stock}.\")\n",
    "    time.sleep(random.uniform(10, 20))\n",
    "conn.close()\n",
    "print(\"Scraping and data storage complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f58c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verification\n",
    "conn = sqlite3.connect(\"stocks.db\")\n",
    "for symbol in stock_symbols: \n",
    "    sanitized_symbol = symbol.replace('^','_')\n",
    "    read_df = pd.read_sql(f\"SELECT * FROM {sanitized_symbol}\", conn, index_col = 'Date')\n",
    "    print(f\"Data for {sanitized_symbol}:\")\n",
    "    print(read_df)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8dfc0-33ed-46de-986a-e0ee67482785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code that works\n",
    "# Reference only\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "# from selenium.webdriver.common.by import By\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# # Initialize the Chrome driver\n",
    "# service = Service(executable_path=ChromeDriverManager().install())\n",
    "# driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# def scrape_table_data(url):\n",
    "#     driver.get(url)\n",
    "\n",
    "#     # Wait for the page to load (adjust time as needed)\n",
    "#     driver.implicitly_wait(10)\n",
    "\n",
    "#     data = []\n",
    "\n",
    "#     try:\n",
    "#         # Locate the table rows\n",
    "#         table_rows = driver.find_elements(By.CSS_SELECTOR, 'table.yf-1jecxey tbody tr')\n",
    "\n",
    "#         # Iterate through each row and extract data\n",
    "#         for row in table_rows:\n",
    "#             # Locate the table cells in each row\n",
    "#             cells = row.find_elements(By.CSS_SELECTOR, 'td.yf-1jecxey')\n",
    "            \n",
    "#             # Extract the text from each cell\n",
    "#             row_data = [cell.text for cell in cells]\n",
    "#             data.append(row_data)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error scraping data: {e}\")\n",
    "#         data = None\n",
    "\n",
    "#     finally:\n",
    "#         return data\n",
    "\n",
    "# # Example URL (replace with your actual URL)\n",
    "# url = 'https://finance.yahoo.com/quote/AAPL/history?period1=1472668800&period2=1693084800'\n",
    "\n",
    "# table_data = scrape_table_data(url)\n",
    "\n",
    "# if table_data:\n",
    "#     # Define the column names\n",
    "#     columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "\n",
    "#     # Create a Pandas DataFrame\n",
    "#     df = pd.DataFrame(table_data, columns=columns)\n",
    "#     print(df)\n",
    "# else:\n",
    "#     print(\"No data scraped.\")\n",
    "\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b461c-f1e0-464e-8506-86e401c8966b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
